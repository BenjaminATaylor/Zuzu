### Pipeline plan:

## Simple version: work with a single test set and produce certain reproducibility metrics

# Input
A dataframe or matrix containing raw gene counts, from nf-core RNAseq
A sample sheet giving sample IDs and values for a single binary categorical variables
(optionally) A specification of the reference condition (important for DE analyses)

# Process

1. Check that the dataframe and matrix are valid and conform
Do the sample names in the two match?
Is there a condition, is it binary and categorical, and does it match the supplied reference level?
Are there non-numeric values within the counts matrix?

2. Clean the counts matrix. This has to be well-standardised so that we have comparable data before moving onto the next steps
Coerce all counts to integers
Cut low counts, two ways: simple per-sample cut and per-group cut (does at least one group meet minimum) (GIVE THE OPTION TO SKIP THIS)
Generate output reports: how many genes cut by each method, how many remain

3. Quality control. Generate some output plots, and perhaps a text report? Can this auto-flag outliers?
PCA/MDS with treatments labeled (can we also label sources of technical variation? Lanes?)
Cook's distances plot
pheatmap of sample distances

4. DESeq2 initial analysis... etc



What's the plan with the quasi data?

These data let us generate power, FDR and ROC AUC for a given method... 
...but we don't want this to be static. We want to measure it across a range of:
    1. Sample sizes (but down to what value? Lowest sample sizes not appropriate for e.g. ML)
    2. Sequencing depths?

So at a first pass, we want to run X times each for X sample sizes (start small for testing purposes)
So at each round, we do this:

1. Set seed and create a quasi-permuted dataset
2. For that dataset, repeat for each method:
3. Calculate degs with that method with that dataset with full sample size
4. Repeat for other sample sizes

So:
For dataset X
And method Y
And sample size Z
We have N datasets